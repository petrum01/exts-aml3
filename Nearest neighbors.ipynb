{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pixels', 'overfeat', 'labels', 'names', 'allow_pickle'])\n",
      "pixels shape : (5000, 3072) , dtype: uint8\n",
      "overfeat shape : (5000, 4096) , dtype: float32\n",
      "labels shape : (5000,) , dtype: int64\n",
      "Categories: ['truck' 'car' 'airplane' 'ship']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "with np.load('cifar4-train.npz', allow_pickle=False) as npz_file:\n",
    "    # Load items into a dictionary\n",
    "    cifar = dict(npz_file.items())\n",
    "\n",
    "print(cifar.keys())\n",
    "\n",
    "pixels = cifar['pixels']\n",
    "overfeat = cifar['overfeat']\n",
    "labels = cifar['labels']\n",
    "names = cifar['names']\n",
    "\n",
    "print('pixels shape :',pixels.shape, ', dtype:', pixels.dtype)\n",
    "print('overfeat shape :',overfeat.shape, ', dtype:', overfeat.dtype)\n",
    "print('labels shape :',labels.shape, ', dtype:', labels.dtype)\n",
    "print('Categories:', names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4000, 4096) (4000,)\n",
      "Test: (1000, 4096) (1000,)\n",
      "class distribution in train set: \n",
      " 3    0.25\n",
      "1    0.25\n",
      "2    0.25\n",
      "0    0.25\n",
      "dtype: float64\n",
      "class distribution in test set: \n",
      " 3    0.25\n",
      "2    0.25\n",
      "1    0.25\n",
      "0    0.25\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# split the Overfeat data into train/test sets w/ same proportion of classes in each subset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    overfeat, labels, train_size=4000, test_size=1000, \n",
    "    stratify=labels , # same class distribution\n",
    "    random_state=0)\n",
    "\n",
    "print('Train:', X_tr.shape, y_tr.shape)\n",
    "print('Test:', X_te.shape, y_te.shape)\n",
    "print('class distribution in train set:','\\n', pd.value_counts(y_tr, normalize=True))\n",
    "print('class distribution in test set:','\\n', pd.value_counts(y_te, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train2: (3200, 4096) (3200,)\n",
      "Val: (800, 4096) (800,)\n",
      "Class distribution in train set: \n",
      " 3    0.25\n",
      "1    0.25\n",
      "2    0.25\n",
      "0    0.25\n",
      "dtype: float64\n",
      "Class distribution in test set: \n",
      " 3    0.25\n",
      "2    0.25\n",
      "1    0.25\n",
      "0    0.25\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Then, split the train set (4,000 points) into a (smaller) train and validation sets\n",
    "# with respectively 3,200 and 800 samples\n",
    "\n",
    "X_tr2, X_val, y_tr2, y_val = train_test_split(\n",
    "    X_tr, y_tr, train_size=3200, test_size=800, \n",
    "    stratify=y_tr , # same class distribution\n",
    "    random_state=0)\n",
    "\n",
    "print('Train2:', X_tr2.shape, y_tr2.shape)\n",
    "print('Val:', X_val.shape, y_val.shape)\n",
    "print('Class distribution in train set:','\\n',pd.value_counts(y_tr2, normalize=True))\n",
    "print('Class distribution in test set:','\\n', pd.value_counts(y_val, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a k-NN classifier with PCA. Tune k and the distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create k-NN classifier\n",
    "pipe = Pipeline([\n",
    "    #('scaler', StandardScaler()), # With standardization\n",
    "    ('scaler', None),\n",
    "    ('pca', PCA(n_components=172)), # PCA preprocessing, number of components to retain 90% of the variance explained.\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        algorithm='brute', # Brute-force search\n",
    "        n_jobs=-1 # As many parallel jobs as possible\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# grid of parameters \n",
    "grid = ParameterGrid({\n",
    "    'scaler': [None, StandardScaler()],\n",
    "    'pca' : [None, PCA(n_components=172)],\n",
    "    'knn__n_neighbors': range(1,100,15), # k\n",
    "    'knn__p': [1, 2], # L1 and L2 distance metrics\n",
    "})\n",
    "\n",
    "# Print the number of combinations\n",
    "print('Number of combinations:', len(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1/56\n",
      "Combination 2/56\n",
      "Combination 3/56\n",
      "Combination 4/56\n",
      "Combination 5/56\n",
      "Combination 6/56\n",
      "Combination 7/56\n",
      "Combination 8/56\n",
      "Combination 9/56\n",
      "Combination 10/56\n",
      "Combination 11/56\n",
      "Combination 12/56\n",
      "Combination 13/56\n",
      "Combination 14/56\n",
      "Combination 15/56\n",
      "Combination 16/56\n",
      "Combination 17/56\n",
      "Combination 18/56\n",
      "Combination 19/56\n",
      "Combination 20/56\n",
      "Combination 21/56\n",
      "Combination 22/56\n",
      "Combination 23/56\n",
      "Combination 24/56\n",
      "Combination 25/56\n",
      "Combination 26/56\n",
      "Combination 27/56\n",
      "Combination 28/56\n",
      "Combination 29/56\n",
      "Combination 30/56\n",
      "Combination 31/56\n",
      "Combination 32/56\n",
      "Combination 33/56\n",
      "Combination 34/56\n",
      "Combination 35/56\n",
      "Combination 36/56\n",
      "Combination 37/56\n",
      "Combination 38/56\n",
      "Combination 39/56\n",
      "Combination 40/56\n",
      "Combination 41/56\n",
      "Combination 42/56\n",
      "Combination 43/56\n",
      "Combination 44/56\n",
      "Combination 45/56\n",
      "Combination 46/56\n",
      "Combination 47/56\n",
      "Combination 48/56\n",
      "Combination 49/56\n",
      "Combination 50/56\n",
      "Combination 51/56\n",
      "Combination 52/56\n",
      "Combination 53/56\n",
      "Combination 54/56\n",
      "Combination 55/56\n",
      "Combination 56/56\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Save accuracy on test set\n",
    "test_scores = []\n",
    "\n",
    "# Enumerate combinations starting from 1\n",
    "for i, params_dict in enumerate(grid, 1):\n",
    "    # Print progress\n",
    "    print('Combination {}/{}'.format(\n",
    "        i, len(grid) # Total number of combinations\n",
    "    ))\n",
    "    \n",
    "    # Set parameters\n",
    "    pipe.set_params(**params_dict)\n",
    "\n",
    "    # Fit a k-NN classifier on smaller train set\n",
    "    pipe.fit(X_tr2, y_tr2)\n",
    "\n",
    "    # Save accuracy on validation set\n",
    "    params_dict['accuracy'] = pipe.score(X_val, y_val)\n",
    "\n",
    "    # Save result\n",
    "    test_scores.append(params_dict)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>knn__n_neighbors</th>\n",
       "      <th>knn__p</th>\n",
       "      <th>pca</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.78000</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.77625</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.77500</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.77375</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.77375</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.77250</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.77125</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.77125</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.77125</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.77000</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.77000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.77000</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.77000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  knn__n_neighbors  knn__p  \\\n",
       "28   0.78125                46       2   \n",
       "25   0.78000                46       1   \n",
       "33   0.77625                61       1   \n",
       "24   0.77500                46       1   \n",
       "29   0.77375                46       2   \n",
       "37   0.77375                61       2   \n",
       "47   0.77250                76       2   \n",
       "46   0.77125                76       2   \n",
       "23   0.77125                31       2   \n",
       "22   0.77125                31       2   \n",
       "21   0.77000                31       2   \n",
       "16   0.77000                31       1   \n",
       "14   0.77000                16       2   \n",
       "17   0.77000                31       1   \n",
       "20   0.76875                31       2   \n",
       "\n",
       "                                                  pca  \\\n",
       "28                                               None   \n",
       "25                                               None   \n",
       "33                                               None   \n",
       "24                                               None   \n",
       "29                                               None   \n",
       "37                                               None   \n",
       "47  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "46  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "23  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "22  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "21                                               None   \n",
       "16                                               None   \n",
       "14  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "17                                               None   \n",
       "20                                               None   \n",
       "\n",
       "                                               scaler  \n",
       "28                                               None  \n",
       "25  StandardScaler(copy=True, with_mean=True, with...  \n",
       "33  StandardScaler(copy=True, with_mean=True, with...  \n",
       "24                                               None  \n",
       "29  StandardScaler(copy=True, with_mean=True, with...  \n",
       "37  StandardScaler(copy=True, with_mean=True, with...  \n",
       "47  StandardScaler(copy=True, with_mean=True, with...  \n",
       "46                                               None  \n",
       "23  StandardScaler(copy=True, with_mean=True, with...  \n",
       "22                                               None  \n",
       "21  StandardScaler(copy=True, with_mean=True, with...  \n",
       "16                                               None  \n",
       "14                                               None  \n",
       "17  StandardScaler(copy=True, with_mean=True, with...  \n",
       "20                                               None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(test_scores)\n",
    "\n",
    "# Print scores\n",
    "scores_df.sort_values(by='accuracy', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top accuracy on validation set: 0.78125  with k: 46 and distance metric: 2\n"
     ]
    }
   ],
   "source": [
    "best = scores_df.sort_values(by='accuracy', ascending=False)[0:1]\n",
    "print('Top accuracy on validation set:', best.iloc[0,0], ' with k:', best.iloc[0,1],\n",
    "    'and distance metric:', best.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN accuracy on the test set: 0.771\n"
     ]
    }
   ],
   "source": [
    "# Create k-NN classifier with tuned parameters\n",
    "knn_best = KNeighborsClassifier(p= best.iloc[0,2], \n",
    "                                n_neighbors= best.iloc[0,1], \n",
    "                                algorithm='brute', \n",
    "                                n_jobs=-1)\n",
    "\n",
    "pipe = Pipeline([('scaler', None),\n",
    "                 ('pca', None),\n",
    "                  #('pca', PCA(n_components=172)),\n",
    "                 ('knn', knn_best)])\n",
    "\n",
    "# Fit it to the entire train data\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# evaluate its accuracy on the test set\n",
    "accuracy_best = pipe.score(X_te, y_te)\n",
    "print ('K-NN accuracy on the test set: {:.3f}'.format(accuracy_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "     steps=[('scaler', None), ('pca', None), ('knn', KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=46, p=2,\n",
       "           weights='uniform'))])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an image from the test set and plot its 10 nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick an image from the test set and plot it with its 10 nearest neighbors from the train one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random image from the test set\n",
    "import random\n",
    "img = X_te[random.randint(1,len(X_te))].reshape(1, -1)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
